{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Lifecycle Project\n",
    "\n",
    "## This is an exercise in 3 parts:\n",
    "### A. Setup and Message Production\n",
    "### B. Message Consumption and Storage\n",
    "### C. Predictive Modeling with Machine Learning\n",
    "$~$  \n",
    "# B. Message Consumption and Storage\n",
    "$~$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Establish Kafka Consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "import sys, os\n",
    "import json\n",
    "from time import sleep\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import KafkaProducer\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish kafka consumers\n",
    "consumer_RawData = KafkaConsumer('RawData', bootstrap_servers=['localhost:9092'], api_version=(0,10,1), consumer_timeout_ms=1000, group_id='lab2', auto_offset_reset='earliest', enable_auto_commit=True,)\n",
    "consumer_Results = KafkaConsumer('Results', bootstrap_servers=['localhost:9092'], api_version=(0,10,1), consumer_timeout_ms=1000, group_id='lab2', auto_offset_reset='earliest', enable_auto_commit=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Consume Data Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL database version: ('PostgreSQL 11.2, compiled by Visual C++ build 1914, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "#establish PostgreSQL database connection\n",
    "conn_string = \"host=localhost port=5432 dbname=messaging user=postgres password=postgres\"\n",
    "connection=psycopg2.connect(conn_string)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('SELECT version()')\n",
    "db_version = cursor.fetchone()\n",
    "print('PostgreSQL database version:',db_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 = last key written to PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "#request last record key from PostgreSQL\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"select max(key) from RawData\")\n",
    "startkey = cursor.fetchone()\n",
    "if startkey[0] == None:\n",
    "    startkey = 0\n",
    "else:\n",
    "    startkey = int(startkey[0])\n",
    "print(startkey,\"= last key written to PostgreSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Raw Data messages consumed from kafka producer\n",
      "5000 Result messages consumed from kafka producer\n"
     ]
    }
   ],
   "source": [
    "#decode json messages and consume with kafka \n",
    "RawDataList=[]\n",
    "ResultsList=[]\n",
    "    \n",
    "for message in consumer_RawData:\n",
    "    decoded_RawData = json.loads(message.value.decode())\n",
    "    #print(decoded_RawData)\n",
    "    RawDataList.append(decoded_RawData)\n",
    "consumer_RawData.close()\n",
    "print(len(RawDataList),\"Raw Data messages consumed from kafka producer\")\n",
    "    \n",
    "for message in consumer_Results:\n",
    "    decoded_Results = json.loads(message.value.decode())\n",
    "    #print(decoded_Results)\n",
    "    ResultsList.append(decoded_Results)\n",
    "consumer_Results.close()\n",
    "print(len(ResultsList),\"Result messages consumed from kafka producer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Send Received Data to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Raw Data records inserted successfully into database\n"
     ]
    }
   ],
   "source": [
    "#append raw data from messages to PostgreSQL\n",
    "for row in RawDataList:\n",
    "    cursor.execute(\"\"\" INSERT INTO rawdata (key, x, y) VALUES (%s,%s,%s)\"\"\", [row['key'],row['x'],row['y']])\n",
    "    connection.commit()\n",
    "print (len(RawDataList), \"Raw Data records inserted successfully into database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Result records inserted successfully into database\n"
     ]
    }
   ],
   "source": [
    "#append results from messages to PostgreSQL\n",
    "for row in ResultsList:\n",
    "    cursor.execute(\"\"\" INSERT INTO results (key, result) VALUES (%s,%s)\"\"\", [row['key'],row['result']])\n",
    "    connection.commit()\n",
    "print (len(ResultsList), \"Result records inserted successfully into database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Prediction key records inserted successfully into database\n"
     ]
    }
   ],
   "source": [
    "#append predictions key from messages to PostgreSQL\n",
    "for row in ResultsList:\n",
    "    cursor.execute(\"INSERT INTO predictions (key) VALUES (%s)\", [row['key']])\n",
    "    connection.commit()\n",
    "print (len(ResultsList), \"Prediction key records inserted successfully into database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostgreSQL Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close connection\n",
    "#cursor.close()\n",
    "#connection.close()\n",
    "#print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear all table records\n",
    "#cursor = connection.cursor()\n",
    "#cursor.execute(\"\"\" DELETE FROM rawdata\"\"\")\n",
    "#cursor.execute(\"\"\" DELETE FROM results\"\"\")\n",
    "#cursor.execute(\"\"\" DELETE FROM predictions\"\"\")\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rollback on error break\n",
    "#cursor = connection.cursor()\n",
    "#cursor.execute(\"\"\" rollback;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
